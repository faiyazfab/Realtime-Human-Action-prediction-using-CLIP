# Realtime-Human-Action-prediction-using-CLIP
This project uses OpenAI's fine-tuned CLIP model for real-time human action prediction from live webcam feeds. By leveraging CLIP's text-image alignment, it identifies actions for applications like patient monitoring, activity recognition, and interactive systems. The system integrates a human action recognition dataset for enhanced performance.
